{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas_datareader as pdr\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import bs4 as bs\n",
    "import requests\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class setup_data:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.raw_df = None\n",
    "        self.tickers = None\n",
    "        self.scaler = MinMaxScaler()\n",
    "    \n",
    "    def get_sp500_tickers(self):\n",
    "        resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "        soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "        table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "        tickers = []\n",
    "        for row in table.findAll('tr')[1:]:\n",
    "            ticker = row.findAll('td')[0].text\n",
    "            tickers.append(ticker)\n",
    "        self.tickers = tickers\n",
    "        return self\n",
    "\n",
    "    def get_data_from_yahoo(self, tkr, start):\n",
    "        tckr = pdr.DataReader(tkr, 'google', start)\n",
    "        return tckr\n",
    "\n",
    "    def pull_raw_data(self, start, end = None, write_path=None):\n",
    "        \n",
    "        if self.tickers is None:\n",
    "            self.get_sp500_tickers()\n",
    "            \n",
    "        if end is None:\n",
    "            end = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        bad_tickers = {\"LMT\":\"NYSE:LMT\", 'NWL':'NYSE:NWL', 'NBL':'NYSE:NBL'}\n",
    "\n",
    "        self.raw_df = pd.DataFrame(index=pd.date_range(start, end)[::-1])\n",
    "        \n",
    "        for t in self.tickers:\n",
    "            if t in bad_tickers.keys():\n",
    "                t=bad_tickers[t]\n",
    "            one_ticker = self.get_data_from_yahoo(t, start)[['Close', 'Volume']]\n",
    "            one_ticker.columns = [x + t for x in one_ticker.columns]\n",
    "            self.raw_df = self.raw_df.merge(one_ticker, \n",
    "                                            left_index=True, right_index=True, how='left')\n",
    "\n",
    "        if write_path is not None:\n",
    "            if not os.path.exists(write_path):\n",
    "                os.makedirs(write_path)\n",
    "            fname = 'sp_500_{0}_{1}.csv'.format(start, end)\n",
    "            self.raw_df.to_csv(os.path.join(write_path, fname))\n",
    "        return self\n",
    "    \n",
    "    def read_raw_data(self, filename):\n",
    "        self.raw_df = pd.read_csv(filename, index_col=0)\n",
    "        self.tickers = self.raw_df.columns\n",
    "        self.raw_df.index = pd.to_datetime(self.raw_df.index)\n",
    "        return self\n",
    "    \n",
    "    def preprocess_stocks(self, df):\n",
    "        \n",
    "        # encode non-trading days as -1\n",
    "        df = df.fillna(-1)\n",
    "        df = pd.DataFrame(self.scaler.fit_transform(df), columns=df.columns)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def transform_y(self, arr):\n",
    "        c = np.zeros((arr.shape[0], arr.shape[1]*2), dtype=arr.dtype)\n",
    "        c[:,::2] = arr\n",
    "        return self.scaler.inverse_transform(c)[:,::2]\n",
    "    \n",
    "    def transform_X(self, arr):\n",
    "        return self.scaler.inverse_transform(arr)\n",
    "    \n",
    "    def make_modeling_data(self, window=30, step=1):\n",
    "        \n",
    "        if self.raw_df is None:\n",
    "            raise Exception(\"Raw data needs to be loaded first by using pull_raw_data() or read_raw_data()\")\n",
    "        \n",
    "        df = self.preprocess_stocks(self.raw_df)\n",
    "        \n",
    "        # based on the previous window days, what is tomorrows's s&p 500 closing prices?\n",
    "        window_ = window + 1\n",
    "        num_samples = len(df)-window_\n",
    "        nstocks = len(df.columns)\n",
    "        M = np.zeros((num_samples, window_, nstocks), dtype=np.float32)\n",
    "        for i in range(0, num_samples):\n",
    "            M[i, :, :] = df.iloc[i:(i +window_)].to_dense()\n",
    "        X = M[:, 1:window_, :]\n",
    "        y = M[:, 0, :]\n",
    "        return X, y\n",
    "    \n",
    "    def make_train_test(self, train_end_date, **kwargs):\n",
    "        \n",
    "        X, y = self.make_modeling_data(**kwargs)\n",
    "        self.date_to_int = {v:k for k, v in enumerate(setup.raw_df.index.strftime('%Y-%m-%d'))}\n",
    "        self.stock_to_int = {v:k for k, v in enumerate(setup.raw_df.columns)}\n",
    "        \n",
    "        ix_test = self.date_to_int[train_end_date]\n",
    "\n",
    "        X_test = X[:ix_test, :, :]\n",
    "        X_train = X[ix_test:, :, :]\n",
    "        y_test = y[:ix_test, ::2]\n",
    "        y_train = y[ix_test:, ::2]\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def make_predictions(keras_model, test_examples):\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def predict_date(keras_model, date):\n",
    "        \n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = setup_data()\n",
    "# setup.pull_raw_data(start = '2006-01-01', write_path = '/home/andrew/data/stocks')\n",
    "setup.read_raw_data('/home/andrew/data/stocks/sp_500_2006-01-01_2017-07-13.csv')\n",
    "X_train, X_test, y_train, y_test = setup.make_train_test(train_end_date = '2017-05-23', window=30, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]), dropout=0.2))\n",
    "model.add(Dense(y_train.shape[1]))\n",
    "model.add(Activation('linear'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4130 samples, validate on 51 samples\n",
      "Epoch 1/24\n",
      "4130/4130 [==============================] - 20s - loss: 0.0688 - val_loss: 0.0873\n",
      "Epoch 2/24\n",
      "4130/4130 [==============================] - 18s - loss: 0.0243 - val_loss: 0.0548\n",
      "Epoch 3/24\n",
      "4130/4130 [==============================] - 19s - loss: 0.0177 - val_loss: 0.0469\n",
      "Epoch 4/24\n",
      "4130/4130 [==============================] - 18s - loss: 0.0154 - val_loss: 0.0419\n",
      "Epoch 5/24\n",
      "4130/4130 [==============================] - 22s - loss: 0.0142 - val_loss: 0.0423\n",
      "Epoch 6/24\n",
      "4130/4130 [==============================] - 19s - loss: 0.0134 - val_loss: 0.0395\n",
      "Epoch 7/24\n",
      "4130/4130 [==============================] - 20s - loss: 0.0130 - val_loss: 0.0399\n",
      "Epoch 8/24\n",
      "4130/4130 [==============================] - 18s - loss: 0.0124 - val_loss: 0.0418\n",
      "Epoch 9/24\n",
      "4130/4130 [==============================] - 20s - loss: 0.0123 - val_loss: 0.0387\n",
      "Epoch 10/24\n",
      "4130/4130 [==============================] - 22s - loss: 0.0124 - val_loss: 0.0362\n",
      "Epoch 11/24\n",
      "4130/4130 [==============================] - 20s - loss: 0.0119 - val_loss: 0.0364\n",
      "Epoch 12/24\n",
      "4130/4130 [==============================] - 19s - loss: 0.0115 - val_loss: 0.0370\n",
      "Epoch 13/24\n",
      "4130/4130 [==============================] - 21s - loss: 0.0112 - val_loss: 0.0379\n",
      "Epoch 14/24\n",
      "4130/4130 [==============================] - 24s - loss: 0.0113 - val_loss: 0.0378\n",
      "Epoch 15/24\n",
      "4130/4130 [==============================] - 21s - loss: 0.0112 - val_loss: 0.0358\n",
      "Epoch 16/24\n",
      "4130/4130 [==============================] - 22s - loss: 0.0111 - val_loss: 0.0356\n",
      "Epoch 17/24\n",
      "4130/4130 [==============================] - 24s - loss: 0.0106 - val_loss: 0.0355\n",
      "Epoch 18/24\n",
      "4130/4130 [==============================] - 20s - loss: 0.0106 - val_loss: 0.0330\n",
      "Epoch 19/24\n",
      "4130/4130 [==============================] - 21s - loss: 0.0103 - val_loss: 0.0321\n",
      "Epoch 20/24\n",
      "4130/4130 [==============================] - 20s - loss: 0.0103 - val_loss: 0.0327\n",
      "Epoch 21/24\n",
      "4130/4130 [==============================] - 20s - loss: 0.0099 - val_loss: 0.0344\n",
      "Epoch 22/24\n",
      "4130/4130 [==============================] - 20s - loss: 0.0093 - val_loss: 0.0319\n",
      "Epoch 23/24\n",
      "4130/4130 [==============================] - 18s - loss: 0.0097 - val_loss: 0.0314\n",
      "Epoch 24/24\n",
      "4130/4130 [==============================] - 18s - loss: 0.0089 - val_loss: 0.0292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f785d7d7c50>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=64,\n",
    "          epochs=24, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "trues = pd.DataFrame(setup.transform_y(y_test), columns=setup.raw_df.columns[::2], index=setup.raw_df.index[:y_test.shape[0]])\n",
    "preds = pd.DataFrame(setup.transform_y(y_pred), columns=setup.raw_df.columns[::2], index=setup.raw_df.index[:y_test.shape[0]])# # .shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-07-13</th>\n",
       "      <td>205.524841</td>\n",
       "      <td>211.089996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-12</th>\n",
       "      <td>202.038071</td>\n",
       "      <td>211.299988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-11</th>\n",
       "      <td>184.829025</td>\n",
       "      <td>209.660004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-10</th>\n",
       "      <td>166.340363</td>\n",
       "      <td>210.489990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-09</th>\n",
       "      <td>-4.551937</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-08</th>\n",
       "      <td>9.921835</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-07</th>\n",
       "      <td>198.232712</td>\n",
       "      <td>209.589996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-06</th>\n",
       "      <td>200.662094</td>\n",
       "      <td>208.020004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-05</th>\n",
       "      <td>200.955505</td>\n",
       "      <td>209.759995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-04</th>\n",
       "      <td>184.707413</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-03</th>\n",
       "      <td>164.486221</td>\n",
       "      <td>209.829987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-02</th>\n",
       "      <td>-4.378772</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-01</th>\n",
       "      <td>14.038601</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-30</th>\n",
       "      <td>202.952148</td>\n",
       "      <td>208.189987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-29</th>\n",
       "      <td>203.787109</td>\n",
       "      <td>207.849991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-28</th>\n",
       "      <td>185.100113</td>\n",
       "      <td>210.619995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-27</th>\n",
       "      <td>180.609024</td>\n",
       "      <td>209.779999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-26</th>\n",
       "      <td>150.573593</td>\n",
       "      <td>212.609985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25</th>\n",
       "      <td>0.656446</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-24</th>\n",
       "      <td>17.926979</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-23</th>\n",
       "      <td>196.057739</td>\n",
       "      <td>212.899994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-22</th>\n",
       "      <td>206.382080</td>\n",
       "      <td>212.219986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-21</th>\n",
       "      <td>198.089172</td>\n",
       "      <td>212.860001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-20</th>\n",
       "      <td>184.292130</td>\n",
       "      <td>213.360001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-19</th>\n",
       "      <td>163.971298</td>\n",
       "      <td>213.360001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-18</th>\n",
       "      <td>-6.459529</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-17</th>\n",
       "      <td>7.275276</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-16</th>\n",
       "      <td>195.209763</td>\n",
       "      <td>213.239990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-15</th>\n",
       "      <td>200.365280</td>\n",
       "      <td>211.289993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-14</th>\n",
       "      <td>200.349197</td>\n",
       "      <td>210.009995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-13</th>\n",
       "      <td>184.216507</td>\n",
       "      <td>209.109985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-12</th>\n",
       "      <td>164.638382</td>\n",
       "      <td>207.389999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-11</th>\n",
       "      <td>-5.617047</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-10</th>\n",
       "      <td>7.346172</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-09</th>\n",
       "      <td>197.779373</td>\n",
       "      <td>206.929993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-08</th>\n",
       "      <td>202.370483</td>\n",
       "      <td>205.939987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-07</th>\n",
       "      <td>196.915604</td>\n",
       "      <td>205.009995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-06</th>\n",
       "      <td>183.538055</td>\n",
       "      <td>205.409988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-05</th>\n",
       "      <td>161.278580</td>\n",
       "      <td>206.220001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-04</th>\n",
       "      <td>-5.157197</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-03</th>\n",
       "      <td>12.272492</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-02</th>\n",
       "      <td>202.525665</td>\n",
       "      <td>206.699997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-01</th>\n",
       "      <td>204.198288</td>\n",
       "      <td>204.349991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-31</th>\n",
       "      <td>197.859741</td>\n",
       "      <td>204.469986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-30</th>\n",
       "      <td>183.925064</td>\n",
       "      <td>202.439987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-29</th>\n",
       "      <td>160.106369</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-28</th>\n",
       "      <td>-6.022563</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-27</th>\n",
       "      <td>11.193650</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-26</th>\n",
       "      <td>196.711136</td>\n",
       "      <td>200.669998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-25</th>\n",
       "      <td>194.205475</td>\n",
       "      <td>199.539993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-24</th>\n",
       "      <td>197.634201</td>\n",
       "      <td>197.489990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  pred        true\n",
       "2017-07-13  205.524841  211.089996\n",
       "2017-07-12  202.038071  211.299988\n",
       "2017-07-11  184.829025  209.660004\n",
       "2017-07-10  166.340363  210.489990\n",
       "2017-07-09   -4.551937   -1.000000\n",
       "2017-07-08    9.921835   -1.000000\n",
       "2017-07-07  198.232712  209.589996\n",
       "2017-07-06  200.662094  208.020004\n",
       "2017-07-05  200.955505  209.759995\n",
       "2017-07-04  184.707413   -1.000000\n",
       "2017-07-03  164.486221  209.829987\n",
       "2017-07-02   -4.378772   -1.000000\n",
       "2017-07-01   14.038601   -1.000000\n",
       "2017-06-30  202.952148  208.189987\n",
       "2017-06-29  203.787109  207.849991\n",
       "2017-06-28  185.100113  210.619995\n",
       "2017-06-27  180.609024  209.779999\n",
       "2017-06-26  150.573593  212.609985\n",
       "2017-06-25    0.656446   -1.000000\n",
       "2017-06-24   17.926979   -1.000000\n",
       "2017-06-23  196.057739  212.899994\n",
       "2017-06-22  206.382080  212.219986\n",
       "2017-06-21  198.089172  212.860001\n",
       "2017-06-20  184.292130  213.360001\n",
       "2017-06-19  163.971298  213.360001\n",
       "2017-06-18   -6.459529   -1.000000\n",
       "2017-06-17    7.275276   -1.000000\n",
       "2017-06-16  195.209763  213.239990\n",
       "2017-06-15  200.365280  211.289993\n",
       "2017-06-14  200.349197  210.009995\n",
       "2017-06-13  184.216507  209.109985\n",
       "2017-06-12  164.638382  207.389999\n",
       "2017-06-11   -5.617047   -1.000000\n",
       "2017-06-10    7.346172   -1.000000\n",
       "2017-06-09  197.779373  206.929993\n",
       "2017-06-08  202.370483  205.939987\n",
       "2017-06-07  196.915604  205.009995\n",
       "2017-06-06  183.538055  205.409988\n",
       "2017-06-05  161.278580  206.220001\n",
       "2017-06-04   -5.157197   -1.000000\n",
       "2017-06-03   12.272492   -1.000000\n",
       "2017-06-02  202.525665  206.699997\n",
       "2017-06-01  204.198288  204.349991\n",
       "2017-05-31  197.859741  204.469986\n",
       "2017-05-30  183.925064  202.439987\n",
       "2017-05-29  160.106369   -1.000000\n",
       "2017-05-28   -6.022563   -1.000000\n",
       "2017-05-27   11.193650   -1.000000\n",
       "2017-05-26  196.711136  200.669998\n",
       "2017-05-25  194.205475  199.539993\n",
       "2017-05-24  197.634201  197.489990"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'true':trues['CloseMMM'], 'pred':preds['CloseMMM']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6828903"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(trues-preds).mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ideas...drop non-trading days, increase regularization, predict +/- instead of price"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
