{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader as pdr\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import bs4 as bs\n",
    "import requests\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class setup_data:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.raw_df = None\n",
    "        self.tickers = None\n",
    "        self.scaler = MinMaxScaler()\n",
    "    \n",
    "    def get_sp500_tickers(self):\n",
    "        resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "        soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "        table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "        tickers = []\n",
    "        for row in table.findAll('tr')[1:]:\n",
    "            ticker = row.findAll('td')[0].text\n",
    "            tickers.append(ticker)\n",
    "        self.tickers = tickers\n",
    "        return self\n",
    "\n",
    "    def get_data_from_yahoo(self, tkr, start):\n",
    "        tckr = pdr.DataReader(tkr, 'google', start)\n",
    "        return tckr\n",
    "\n",
    "    def pull_raw_data(self, start, end = None, write_path=None):\n",
    "        \n",
    "        if self.tickers is None:\n",
    "            self.get_sp500_tickers()\n",
    "            \n",
    "        if end is None:\n",
    "            end = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        bad_tickers = {\"LMT\":\"NYSE:LMT\", 'NWL':'NYSE:NWL', 'NBL':'NYSE:NBL'}\n",
    "\n",
    "        self.raw_df = pd.DataFrame(index=pd.date_range(start, end)[::-1])\n",
    "        \n",
    "        for t in self.tickers:\n",
    "            if t in bad_tickers.keys():\n",
    "                t=bad_tickers[t]\n",
    "            one_ticker = self.get_data_from_yahoo(t, start)\n",
    "            self.raw_df = self.raw_df.merge(one_ticker.Close.to_frame(name=t), \n",
    "                                            left_index=True, right_index=True, how='left')\n",
    "\n",
    "        if write_path is not None:\n",
    "            if not os.path.exists(write_path):\n",
    "                os.makedirs(write_path)\n",
    "            fname = 'sp_500_{0}_{1}.csv'.format(start, end)\n",
    "            self.raw_df.to_csv(os.path.join(write_path, fname))\n",
    "        return self\n",
    "    \n",
    "    def read_raw_data(self, filename):\n",
    "        self.raw_df = pd.read_csv(filename, index_col=0)\n",
    "        self.tickers = self.raw_df.columns\n",
    "        return self\n",
    "    \n",
    "    def preprocess_stocks(self, df):\n",
    "        \n",
    "        # encode non-trading days as -1\n",
    "        df = df.fillna(-1)\n",
    "        df = pd.DataFrame(self.scaler.fit_transform(df), columns=df.columns)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def transform_predictions(self, arr):\n",
    "        return self.scaler.inverse_transform(arr)\n",
    "    \n",
    "    def make_modeling_data(self, window=30, step=1):\n",
    "        \n",
    "        if self.raw_df is None:\n",
    "            raise Exception(\"Raw data needs to be loaded first by using pull_raw_data() or read_raw_data()\")\n",
    "        \n",
    "        df = self.preprocess_stocks(self.raw_df)\n",
    "        \n",
    "        # based on the previous window days, what is tomorrows's s&p 500 closing prices?\n",
    "        window_ = window + 1\n",
    "        num_samples = len(df)-window_\n",
    "        nstocks = len(df.columns)\n",
    "        M = np.zeros((num_samples, window_, nstocks), dtype=np.float32)\n",
    "        for i in range(0, num_samples):\n",
    "            M[i, :, :] = df.iloc[i:(i +window_)].to_dense()\n",
    "        X = M[:, 1:window_, :]\n",
    "        y = M[:, 0, :]\n",
    "        return X, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = setup_data()\n",
    "setup.pull_raw_data(start = '2006-01-01', write_path = '/home/andrew/data/stocks')\n",
    "# setup.read_raw_data('/home/andrew/data/stocks/sp_500_2016-01-01_2017-06-22.csv')\n",
    "X, y = setup.make_modeling_data(window=30, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## training and test data\n",
    "days_test = 30\n",
    "\n",
    "X_test = X[:days_test, :, :]\n",
    "X_train = X[days_test:, :, :]\n",
    "y_test = y[:days_test]\n",
    "y_train = y[days_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X.shape[1], X.shape[2]), dropout=0.2))\n",
    "model.add(Dense(y.shape[1]))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=64,\n",
    "          epochs=24, \n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 is the first day of test data, 1 is the second, etc\n",
    "prediction_day = 1\n",
    "X_temp = np.zeros((1, X_test.shape[1], X_test.shape[2]))\n",
    "X_temp[0] = np.concatenate([X_test[0, (days_test-prediction_day):days_test], X_train[0, 0:(days_test-prediction_day)]])\n",
    "\n",
    "preds = model.predict(X_temp, verbose=0)\n",
    "true = y_test[days_test-prediction_day-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'pred':setup.transform_predictions(preds).ravel(),\n",
    "              'true':setup.transform_predictions(true).ravel()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
